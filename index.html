<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="Generalization-of-FM-for-Biometric">
  <meta property="og:title" content="Generalization-of-FM-for-Biometric"/>
  <meta property="og:description" content="Trade-offs in Cross-Domain Generalization of Foundation Model Fine-Tuned for
Biometric Applications"/>
  <meta property="og:url" content="https://taharchettaoui.github.io/Generalization-of-FM-for-Biometric_web/"/>
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <meta property="og:image" content="static/images/carousel1.jpg" />
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/>


  <!-- <meta name="twitter:title" content="TWITTER BANNER TITLE META TAG"> -->
  <!-- <meta name="twitter:description" content="TWITTER BANNER DESCRIPTION META TAG"> -->
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <!-- <meta name="twitter:image" content="static/images/your_twitter_banner_image.png"> -->
  <!-- <meta name="twitter:card" content="summary_large_image"> -->
  <!-- Keywords for your paper to be indexed by -->
  <!-- <meta name="keywords" content="KEYWORDS SHOULD BE PLACED HERE"> -->
  <!-- <meta name="viewport" content="width=device-width, initial-scale=1"> -->
  
  <title> Trade-offs in Cross-Domain Generalization of Foundation Model Fine-Tuned for
Biometric Applications </title>
  <link rel="icon" type="image/x-icon" href="static/images/web_icon_face.ico">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
</head>
<body>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">Trade-offs in Cross-Domain Generalization of Foundation Model Fine-Tuned for
Biometric Applications</h1>
            <div class="is-size-5 publication-authors">
              <!-- Paper authors -->
              <span class="author-block">
                <a href="FIRST AUTHOR PERSONAL LINK" target="_blank">Tahar Chettaoui<sup>1</sup></a>,</span>
                <span class="author-block">
                  <a href="SECOND AUTHOR PERSONAL LINK" target="_blank">Naser Damer<sup>1,2</sup></a>,</span>
                  <span class="author-block">
                    <a href="THIRD AUTHOR PERSONAL LINK" target="_blank">Fadi Boutros<sup>1</sup></a>
                  </span>
                  </div>

                  <div class="is-size-5 publication-authors">
                    <span class="author-block">Fraunhofer IGD<sup>1</sup> & Technische Universität Darmstadt<sup>2</sup> <br></span>
                    <!--  <span class="eql-cntrb"><small><br><sup>*</sup>Indicates Equal Contribution</small></span> -->
                  </div>

                  <div class="column has-text-centered">
                    <div class="publication-links">
                         <!-- Arxiv PDF link -->
                      <span class="link-block">
                        <a href="TODO" target="_blank"
                        class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                          <i class="fas fa-file-pdf"></i>
                        </span>
                        <span>Paper</span>
                      </a>
                    </span>

                    <!-- Supplementary PDF link -->
                    <!--<span class="link-block"> -->
                      <!--<a href="static/pdfs/supplementary_material.pdf" target="_blank" -->
                      <!--class="external-link button is-normal is-rounded is-dark"> -->
                      <!--<span class="icon"> -->
                        <!--<i class="fas fa-file-pdf"></i> -->
                      <!--</span> -->
                      <!--<span>Supplementary</span> -->
                    <!--</a> -->
                  <!--</span> -->

                  <!-- Github link -->
                  <span class="link-block">
                    <a href="TODO" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>

                <!-- ArXiv abstract Link -->
                <span class="link-block">
                  <a href="TODO" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- Teaser -->
<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
     <img src="static/images/plot_1.png" alt="Average verification accuracies" />
      <h2 class="subtitle has-text-centered">
        Generalization Loss (GELO) comparison across models under zero-shot and linear-probe settings. GELO is defined as the ratio of the average (AVG) performance after fine-tuning to the average performance before fine-tuning, providing a measure of generalization loss after fine-tuning. 
      </h2>
    </div>
  </div>
</section>
<!-- End teaser -->

<!-- Paper abstract -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Foundation models such as CLIP have demonstrated exceptional zero- and few-shot transfer capabilities across diverse vision tasks. However, when fine-tuned for highly specialized biometric tasks, face recognition (FR), morphing attack detection (MAD), and presentation attack detection (PAD), these models may suffer from over-specialization.  Thus, they may lose one of their foundational strengths, cross-domain generalization. In this work, we systematically quantify these trade-offs by evaluating three instances of CLIP fine-tuned for FR, MAD and PAD.  We evaluate each adapted model as well as the original CLIP baseline on 14 general vision datasets under zero-shot and linear-probe protocols, alongside common FR, MAD and PAD benchmarks. Our results indicate that finetuned models suffer from over-specialization, especially when finetuned for complex tasks of FR. Also, our results pointed out that task complexity and classification head design, multi-class (FR) vs. binary (MAD and PAD), correlate with the degree of catastrophic forgetting. The FRoundation model with the ViT-L backbone outperforms other approaches on the large scale FR benchmark IJB-C, achieving an improvement of up to 58.52%. However, it experiences a substantial performance drop on ImageNetV2, reaching only 51.63% compared to 69.84% achieved by the baseline CLIP model. Moreover, the larger CLIP architecture consistently preserves more of the model’s original generalization ability than the smaller variant, indicating that increased model capacity may help mitigate over-specialization.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->

<!-- Audio -->
<!--
<section class="section hero is-small">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Discussion</h2> 
        <div style="text-align: center; margin-left: -100px;">
          <audio controls style="width: 500px;"> <source src="static/videos/discussion.wav" type="audio/mpeg"> </audio>
        </div>
      </div>
    </div>
  </div>
</section>
 -->
  
<!-- Image carousel -->
<section class="hero is-light">
  <div class="hero-body">
    <div class="container">
      <div id="results-carousel" class="carousel results-carousel">
       <div class="item">
        <img src="static/images/carousel_1.png" alt="ViT Training Pipeline" />
        <h2 class="subtitle has-text-centered">
          Evaluation of zero-shot cross-task generalization across diverse benchmarks presented as the classification accuracy (%). CLIP outperforms the fine-tuned models on most benchmarks. FRoundation exhibits the weakest overall performance, indicating that the adapted model tends to over-specialize to the FR task, which limits its ability to generalize to other tasks.
        </h2>
      </div>

      <div class="item">
        <img src="static/images/carousel_2.png" alt="ViT Training Pipeline" />
        <h2 class="subtitle has-text-centered">
          Evaluation of linear-probe cross-task generalization across diverse benchmarks presented as the classification accuracy (%). While zero-shot performance shows a correlation with linear-probe accuracy, it remains largely sub-optimal.
        </h2>
      </div>
        
      <div class="item">
        <img src="static/images/carousel_3.png" alt="LoRA Integration MHA" />
        <h2 class="subtitle has-text-centered">
          Baseline and dedicated biometric models performance on FR, PAD, and MAD benchmarks all metrics presented in (%). Each approach adapted to a specific biometric task outperforms the others within its domain. While FRoundation achieves better results on FR benchmarks, it underperforms in generalization over other biometric tasks, revealing the limitations of task-specific over-specialization. Similar conclusions can be made for MADation and FoundPAD.
        </h2>
      </div>
  </div>
</div>
</div>
</section>
<!-- End image carousel -->


<!-- Youtube video -->
<!--<section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container">
      <h2 class="title is-3">Video Presentation</h2>
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <div class="publication-video">
            <iframe src="https://www.youtube.com/embed/JkaxUblCGz0" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
          </div>
        </div>
      </div>
    </div>
  </div>
</section> -->
<!-- End youtube video -->


<!-- Video carousel -->
<!-- <section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <h2 class="title is-3">Another Carousel</h2>
      <div id="results-carousel" class="carousel results-carousel">
        <div class="item item-video1">
          <video poster="" id="video1" autoplay controls muted loop height="100%">
            <source src="static/videos/carousel1.mp4"
            type="video/mp4">
          </video>
        </div>
        <div class="item item-video2">
          <video poster="" id="video2" autoplay controls muted loop height="100%">
            <source src="static/videos/carousel2.mp4"
            type="video/mp4">
          </video>
        </div>
        <div class="item item-video3">
          <video poster="" id="video3" autoplay controls muted loop height="100%">\
            <source src="static/videos/carousel3.mp4"
            type="video/mp4">
          </video>
        </div>
      </div>
    </div>
  </div>
</section> -->
<!-- End video carousel -->

<!-- Paper poster -->
<!-- 
<section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container">
      <h2 class="title">Poster</h2>
        <iframe  src="static/pdfs/sample.pdf" width="100%" height="550"> </iframe>
      </div>
    </div>
  </section>
-->
<!--End paper poster -->

<!--BibTex citation -->
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>
      ...
</code></pre>
    </div>
</section>
<!--End BibTex citation -->


  <footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <font size="1">  
            <p>
              This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a> which was adopted from the <a href="https://nerfies.github.io" target="_blank">Nerfies</a> project page.
              This website is licensed under a <a rel="license"  href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank"> Creative Commons Attribution-ShareAlike 4.0 International License</a>.
            </p>
          </font>
        </div>
      </div>
    </div>
  </div>
</footer>

<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

  </body>
  </html>
